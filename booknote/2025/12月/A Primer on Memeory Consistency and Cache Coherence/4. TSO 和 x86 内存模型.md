#TSO #x86
## 4.1 TSO/X86 的动机
在多核情况下，写缓冲区不再是单核情况下的不可见，写缓冲区会导致违反SC，但是写缓冲区是高性能的，为了不放弃高性能的写缓冲区。


考虑以下的模型
![[Table 4.1.png]]

这个假设是错误的。考虑表 4.1 中的示例代码（与上一章的表 3.3 相同）。假设多核处理器具有顺序核心，其中每个核心都有一个单入口写入缓冲区并按以下顺序执行代码。

1. 核心 C1 执行存储 S1，但在其写缓冲区中缓冲新存储的 NEW 值。
2. 同样，核心 C2 执行存储 S2 并将新存储的 NEW 值保存在其写缓冲区中。
3. 接下来，两个核心执行各自的加载 L1 和 L2，并获得旧值 0。
4. 最后，两个核心的写缓冲区使用新存储的值 NEW 更新内存。

最终结果是 (r1, r2) = (0, 0)。正如我们在上一章中看到的，这是 SC 禁止的执行结果。没有写缓冲区，硬件就是 SC，但有了写缓冲区，它就不是了，这使得写缓冲区在多核处理器中在架构上是可见的。

对可见的写入缓冲区的一种响应是关闭它们，但由于潜在的性能影响，供应商一直不愿这样做。另一种选择是使用激进的、推测性的 SC 实现，使写入缓冲区再次不可见，但这样做会增加复杂性，并且会浪费电力来检测违规和处理错误推测。

SPARC 和后来的 x86 选择的选项是放弃 SC，转而支持内存一致性模型，允许在每个核心上直接使用先进先出 (FIFO) 写入缓冲区。这个被称为 TSO 的新模型允许结果“(r1, r2) = (0, 0)”。这个模型让一些人感到惊讶，但事实证明，对于大多数编程习惯来说，它的行为就像 SC 一样，并且在所有情况下都得到了明确的定义。

## TSO/X86 的实现
TSO/x86 的实现问题与 SC 类似，只是增加了每个核心中的 FIFO writer buffer。


## TSO/X86 的思想
随着执行的进行，SC 要求每个核心为连续操作的所有四种组合保留其加载和存储的程序顺序：

- Load -> Load
- Load -> Store
- Store -> Store
- Store -> Load /* Included for SC but omitted for TSO */

在 TSO/X86 中 load 可以和停留在缓存中的 store  重新排序，即 load 可以读到 store 之前的缓冲区。

这在大多数程序中是可以保证正确的， 但在有的情况会发生错误

### 一个经典例子
```c
假设初始 A = 0, B = 0。

核心 1 执行：
S1: A = 1;  // Store
L1: r1 = B; // Load

核心 2 执行：
S2: B = 1;  // Store
L2: r2 = A; // Load
```

在 SC 下：结果 (r1, r2) = (0, 0) 不可能出现。因为每个核心的 Store → Load 顺序必须保留，执行顺序必须交错，总会有一个核心先看到对方的写入。
在 TSO 下：结果 (r1, r2) = (0, 0) 是可能的！
核心 1 的 L1 可以绕过还在自己写缓冲区里的 S1，于是它读到 B=0。
核心 2 的 L2 可以绕过还在自己写缓冲区里的 S2，于是它读到 A=0。
两个 Store (A=1, B=1) 随后才提交到内存，但为时已晚。
这个反直观的结果正是由于 TSO 放宽了 Store → Load 顺序导致的。要避免它，程序员需要在 Store 和 Load 之间插入内存屏障。


## TSO/X86 的实现
TSO/x86 的实现问题与 SC 类似，只是增加了每个核心中的 FIFO writer buffer。

多线程为 TSO 引入了一个微妙的写入缓冲区问题。 TSO 写缓冲区在逻辑上对每个线程上下文（虚拟内核）都是私有的。因此，在多线程内核上，一个线程上下文不应该绕过另一个线程上下文的写缓冲区。这种逻辑分离可以通过每个线程上下文的写入缓冲区来实现，或者更常见的是，通过使用共享的写入缓冲区来实现，该缓冲区的条目由线程上下文标识符标记，只有在标记匹配时才允许绕过。


## TSO/X86 的原子指令实现
1. TSO 中原子 RMW 指令的实现问题类似于 SC 中原子 RMW 指令的实现问题。关键区别在于 TSO 允许 load pass（即，在之前排序）已写入 write buffer 的较早的 store。对 RMW 的影响是“写入”（即存储）可能会被写入 write buffer。

2. RMW 在 TSO 中的基本实现
	RMW 可视为一个 load（读） 紧跟着一个 store（写），且两者必须原子执行（即中间不能插入其他操作）。
	TSO 排序规则：
	RMW 的 load 部分不能绕过更早的 load（load→load 必须保持顺序）。
	RMW 的 load 部分也不能绕过更早的 store（即使该 store 还在写缓冲区中）。
	原因：如果 load 绕过更早的 store，那么 RMW 的 store 部分也必须绕过它（因为 RMW 是原子对）。但 TSO 禁止 store 之间互相绕过，因此 load 也不能绕过更早的 store。

3. 实现约束
	写缓冲区必须排空：RMW 的 load 部分必须等待所有更早的 store 提交到内存后才能执行。
	缓存权限要求：
	RMW 的 load 部分需要读写权限（而普通 load 只需读权限），因为紧接着的 store 需要立即写入。
	缓存控制器在 load 和 store 之间不能放弃对该缓存块的权限，以保持原子性。
	效果：原子 RMW 会阻塞直到写缓冲区排空，并独占缓存块权限。

4. 优化实现（无需完全排空写缓冲区）
	更高效的实现可以避免完全排空写缓冲区，但需满足以下条件：

	条件 (a)：写缓冲区中所有条目对应的缓存块，在 RMW 提交前必须已获得读写权限，并保持到 RMW 完成。
	条件 (b)：核心需实现 MIPS R10000 式的加载推测检查。
	逻辑效果：所有更早的 store 和 load 会作为一个原子块，在 RMW 之前一次性提交，从而减少停顿。

### 实现 FENCE
#FENCE

支持 TSO 的系统不支持 store -> load 排序， 当程序员确实需要这种排序来 load store 的结果时，  程序员必须在 store 和 load 之间添加一条 **FENCE** 指令来明确该排序。

**FENCE** 的语义规定，在程序顺序中 FENCE 之前的所有指令必须在程序顺序中 FENCE 之后的任何指令之前排序。对于支持 TSO 的系统，FENCE 因此禁止负载绕过较早的存储。

因为 TSO 只允许一种类型的重新排序，所以 FENCE 相当少见，而且 FENCE 指令的实现也不是很关键。一个简单的实现（例如在执行 FENCE 时排空写入缓冲区，并且在较早的 FENCE 提交之前不允许执行后续加载）可能会提供可接受的性能。

然而，对于允许更多重新排序的一致性模型（在下一章中讨论），FENCE 指令更频繁，它们的实现会对性能产生重大影响。


## TSO 非推测性优化
#推测性优化 #CPU流水线
“非推测性”意味着这些优化不会执行可能被回滚的操作，从而避免了推测执行所需的复杂硬件支持（如检查点、回滚机制）。它们通过重新设计内存操作的提交规则或利用缓存一致性协议的延迟特性来实现性能提升。

### **核心思想：非推测性优化**
“非推测性”意味着这些优化**不会执行可能被回滚的操作**，从而避免了推测执行所需的复杂硬件支持（如检查点、回滚机制）。它们通过**重新设计内存操作的提交规则**或**利用缓存一致性协议的延迟特性**来实现性能提升。

---

### **1. 非推测性的 TSO 重排序**

*   **问题**：传统 TSO 只允许 `Store -> Load` 重排。能否在不引入推测的情况下，也允许 `Load -> Load` 或 `Load -> Store` 重排？
*   **解决方案**：论文 [11, 12, 13] 表明，这是可能的，关键在于**利用缓存一致性延迟作为执行顺序的“刹车”**。
*   **工作原理**：
    *   硬件允许后续的 Load 或 Store **提前进入内存子系统**（即开始执行），但在逻辑上，它们必须等待前面的操作**在一致性协议中变得全局可见**后才能**提交**（即变得不可撤销）。
    *   **一致性延迟作为执行栅栏**：例如，如果允许 `Load A -> Load B` 重排，当 `Load B` 先执行但需要获取缓存行权限时，如果发现该权限的获取依赖于更早的 `Load A` 的完成（例如，A 和 B 地址相同，或涉及同一缓存行），那么一致性协议会**自动延迟** `Load B` 的完成，直到 `Load A` 获得其权限。这种延迟在硬件上自然发生，无需显式停顿流水线。
*   **关键挑战与解决**：这种依赖延迟可能形成**死锁循环**（例如，核心1等待核心2，核心2等待核心1）。上述论文通过精心设计的一致性协议或额外的硬件机制（如优先级机制、依赖跟踪）来打破可能的循环，确保系统不会死锁。

---

### **2. 无需排空写缓冲区的 RMW 实现**

*   **问题**：4.4.1 节提到，为了保证 RMW 原子性，其 Load 部分不能绕过 Write Buffer 中更早的 Store，这导致需要排空 Write Buffer 或使用复杂的推测执行。
*   **解决方案（Rajaram 等人 [10]）**：**重新（弱化）定义 RMW 的“原子性”语义**，使其更符合实际使用需求，从而允许硬件优化。
*   **语义对比**：
    *   **传统严格语义**：RMW 的读和写必须在 **TSO 全局内存顺序中连续出现**。没有任何其他操作可以插在它们中间。
    *   **松弛语义**：只要 **没有对 RMW 操作相同地址的写入** 出现在其读和写之间，RMW 就被认为是原子的。**允许其他地址的操作插入**。
*   **为什么这个松弛是可行的？**
    *   它**完全满足同步原语的需求**。例如，实现一个自旋锁（`test-and-set`）：关键是没有其他核心能在我读锁和写锁之间成功写锁。其他核心写其他变量（如受保护的数据）是允许的，只要它们不碰这个锁变量本身。
    *   它匹配了程序员对“原子操作”的**直观理解**：保护的是**特定内存位置**的原子性，而不是一个绝对的时间窗口。
*   **实现优势**：
    *   在这种定义下，RMW 的 Load 部分**可以安全地绕过 Write Buffer 中地址不同的早期 Store**，因为这些 Store 不会破坏 RMW 目标地址的原子性。
    *   因此，**无需排空整个 Write Buffer**，也**无需 MIPS R10000 式的推测检查**。
*   **新挑战与解决**：
    *   仍然需要确保：在 RMW 的 Load 执行后、其 Store 提交前，**没有其他核心写入 RMW 的目标地址**。
    *   这可以通过**获取并持有该地址的缓存独占权限**来实现，并保持这个权限直到 RMW 的 Store 提交。
    *   这里存在**死锁风险**：如果核心A持有地址X的权限进行RMW，同时等待其Write Buffer中地址Y的Store提交，而核心B正持有地址Y的权限并等待地址X，就会死锁。
    *   Rajaram 等人的论文提出了避免这种死锁的协议，可能通过**按全局顺序获取权限**或**引入超时与回退机制**。

---

### **3. 越过 FENCE 的重排序**

*   **问题**：`FENCE`（内存屏障）指令强制其前后的内存操作保持顺序，通常实现为排空Write Buffer等，代价很高。
*   **优化目标**：让 `FENCE` **之后**的内存操作能够**非推测性地、提前开始执行甚至完成**，只要在逻辑上保证它们不会在 `FENCE` 之前的所有操作**全局提交**之前提交。
*   **实现技术**（论文 [3, 4, 6, 8]）：
    1.  **一致性延迟**：允许 `FENCE` 后的操作提前发出，但利用一致性协议来“卡住”它们的提交。例如，`FENCE` 后的 Store 可以进入 Write Buffer，但给它标记一个“等待FENCE前序操作完成”的标签。只有当所有前序操作都获得缓存权限并变得可提交后，这个标签才被清除，允许该 Store 提交。
    2.  **前序序列化**：不是让后序操作等待，而是**加速前序操作的完成**。例如，当遇到 `FENCE` 时，硬件可以优先处理所有 `FENCE` 前的未完成操作，快速为它们获取所需权限，使它们尽快达到可提交状态。
    3.  **组合技术**：结合以上两者，动态管理前后操作的进度。

---

### **总结表格**

| 优化技术 | 核心思想 | 关键实现手段 | 主要收益 |
| :--- | :--- | :--- | :--- |
| **非推测性TSO重排序** | 放宽 `Load->Load/Store` 顺序，用一致性延迟隐式保证最终顺序。 | 依赖缓存一致性协议的固有延迟作为同步机制。 | 提升指令级并行度，无需推测硬件。 |
| **无写缓冲区排空的RMW** | 重新定义RMW原子性为“保护特定地址”，而非“绝对时间连续”。 | 允许RMW的Load绕过地址不同的早期Store；依赖权限保持与死锁避免协议。 | 消除RMW前的写缓冲区排空停顿。 |
| **越过FENCE的重排序** | 允许FENCE后的操作提前执行，但延迟其全局提交。 | 使用一致性延迟标记或前序操作序列化。 | 减少FENCE带来的流水线气泡，提升吞吐量。 |
