#宽松内存一致性
在第三章和第四章中我们讨论了 SC 和 TSO 这样的强内存模型，强模型通常尊重每个线程的程序顺序(program order)

# 5.1 动机

## 5.1.1 重新排序内存操作的机会
考虑表 5.1 中描述的示例，大多数程序员会期望 r2 将始终获得值NEW
![[Table 5.1.png]]
SC/TSO 除了必要的排序外还需要排序 S1->S2 和 L2->L3, 保留这些附加排序可能会限制实现优化并提升性能，但程序不需要这些附加排序来执行正确的操作。

## 5.1.2 利用重新排序的机会

## Non-FIFO, Coalescing Write Buffer
在 TSO 中使用 每个核心私有的FIFO写入缓冲区提高了性能，更加优化的设计将将使用允许合并写入的FIFO写入缓冲区，这违反了 TSO，因为TSO要求存储按照程序顺序出现。

## Simpler Support for Core Speculation
在具有强一致性模型的系统中，核心可能会在准备好提交之前推测性地执行超出程序顺序的加载。回想一下支持 SC 的 MIPS R10000 核心如何使用这种推测来获得比没有推测的朴素实现更好的性能。然而，问题是支持 SC 的推测核心通常必须包含检查推测是否正确的机制，即使错误推测很少见 。 R10000 通过将逐出缓存块的地址与核心已推测加载但尚未提交的地址列表（即内核加载队列的内容）进行比较来检查推测。这种机制增加了硬件的成本和复杂性，它消耗了额外的功率，并且它代表了另一种可能限制指令级并行性的有限资源。在具有宽松内存一致性模型的系统中，核心可以不按程序顺序执行加载，而无需将这些加载的地址与传入的连贯性请求的地址进行比较。这些加载相对于宽松一致性模型不是推测性的（尽管它们可能是推测性的，例如，分支预测或同一线程对同一地址的早期存储）。

# 5.2 宽松一致性模型(XC) 示例
出于教学目的，本节介绍了一个示例宽松一致性模型 (XC)，该模型捕获了宽松内存一致性模型的基本思想和一些实现潜力。XC 假设存在全局内存顺序，对于 SC 和 TSO 的强模型以及 Alpha [33] 和 SPARC 的宽松内存顺序 (relaxed memory order, RMO) [34] 的大部分已失效的宽松模型也是如此。

## 5.2.1 XC 模型的基本思想
XC 提供了 FENCE 指令，以便程序员可以指示何时需要顺序；否则，默认情况下，加载和存储是无序的。

其他的宽松一致性模型将 FENCE 称为屏障、内存屏障、membar 或同步。让核心 Ci 执行一些加载和/或存储 Xi，然后是 FENCE 指令，然后再执行一些加载和/或存储 Yi。FENCE 确保内存顺序将所有 Xi 操作排序在 FENCE 之前，而 FENCE 又在所有 Yi 操作之前。

FENCE 指令不指定地址。同一核心的两个 FENCE 也保持有序。但是，FENCE 不会影响其他核心的内存操作顺序（这就是为什么 "fence" 可能是比 "barrier" 更好的名称）。一些架构包括多个具有不同顺序属性的 FENCE 指令；例如，一个体系结构可以包括一个 FENCE 指令，该指令强制执行所有顺序，除了从存储到后续加载。然而，在本章中，我们只考虑对所有类型的操作进行排序的 FENCE。


XC 的内存顺序保证尊重（保留）程序顺序：

- Load -> FENCE
- Store -> FENCE
- FENCE -> FENCE
- FENCE -> Load
- FENCE -> Store

XC 维护 TSO 规则，用于仅对同一地址进行两次访问：

- Load -> Load to the same address
- Load -> Store to the same address
- Store -> Store to the same address 这些规则强制执行顺序处理器模型（即顺序核心语义）并禁止可能让程序员感到惊讶的行为。 例如，Store -> Store 规则防止执行 "A = 1" 然后 "A = 2" 的临界区在 A 设置为 1 的情况下奇怪地完成。同样，Load -> Load 规则确保如果 B 最初为 0 并且另一个线程执行 "B = 1"，则当前线程无法执行 "r1 = B" 然后 "r2 = B"，其中 r1 得到 1，r2 得到 0，就好像 B 的值从新变旧。

**只要有足够的FENCE， XC 这种宽松模型在程序员看来就像SC**

## 实现 XC
本节讨论实现 XC。 我们采用类似于前两章实现 SC 和 TSO 的方法，其中我们将核心操作的重新排序与缓存连贯性分开。回想一下，TSO 系统中的每个核心都通过 FIFO 写缓冲区与共享内存分开。对于 XC，每个核心将通过一个更通用的重新排序单元与内存分开，该重新排序单元可以重新排序加载和存储。

加载、存储和 FENCE 将每个核心 Ci 留在 Ci 的程序顺序 <p 中，并进入 Ci 的重新排序单元的尾部 (tail)。 Ci 的重新排序单元对操作进行排队，并将它们从尾部传递到头部 (head)，按照程序顺序或按照下面指定的规则重新排序。当 FENCE 到达重新排序单元的头部时，它会被丢弃。 当交换机选择核心 Ci 时，它在 Ci 的重新排序单元的头部执行加载或存储。
![[Figure 5.2.png]]

 系统架构与数据流（图 5.3a）
```text
核心 Ci (按程序顺序 <p 执行)
        ↓
[ 重排序单元 (Reorder Unit) ]  <-- 尾部 (Tail)：接收来自核心的操作
        | (内部可重排操作)
        ↓
头部 (Head) <-- 操作在此等待被“交换机”选择执行
        ↓
交换机 (Switch) / 内存系统
```

- 操作入口：核心 Ci 按程序顺序 (<p) 将 Load、Store、FENCE 指令送入其重排序单元的尾部。
- 内部重排序：重排序单元内部有一个队列，但它不是严格 FIFO 的。它可以根据规则对操作进行重新排序，然后将它们从尾部移动到头部。
- 操作出口：当“交换机”（或内存系统的仲裁器）选择核心 Ci 时，它执行的是位于 Ci 重排序单元头部的那个操作（可能是 Load 或 Store）。
- FENCE 的处理：FENCE 指令本身不执行内存操作。当它到达重排序单元的头部时，其作用已完成（即强制了顺序），因此直接被丢弃。


### 重排序单元必须遵守的规则
这些规则直接对应 XC 内存模型（第 5.2.3 节）为程序员定义的规则，现在在硬件层面强制执行：

- 规则 1：关于 FENCE 的顺序
	FENCE 是一个严格的顺序点，任何跨越它的操作都不能被重排。
	Load -> FENCE：FENCE 前的 Load 不能在 FENCE 之后执行。
	Store -> FENCE：FENCE 前的 Store 不能在 FENCE 之后执行。
	FENCE -> FENCE：多个 FENCE 之间保持顺序。
	FENCE -> Load：FENCE 后的 Load 不能在 FENCE 前执行。
	FENCE -> Store：FENCE 后的 Store 不能在 FENCE 前执行。
	本质：FENCE 在重排序单元中充当了一个屏障，所有在它之前的操作必须全部到达头部并执行/丢弃后，它之后的操作才能继续前进。
- 规则 2：关于同一地址的操作顺序
	对于访问相同内存地址的操作，必须保持顺序以保证单线程语义（连贯性）。
	Load A -> Load A：对同一地址的两次读，顺序必须保持（否则可能读到旧值）。
	Load A -> Store A：读后写 (RAW)，顺序必须保持（否则读不到自己刚写的值）。
	Store A -> Store A：对同一地址的两次写，顺序必须保持（否则最终值可能错误）。
	本质：这是为了维护单核心的程序顺序依赖，防止数据竞争导致的不可预测行为。
- 规则 3：旁路（Store Forwarding）
	如果核心执行了一个 Store，随后又执行了一个 Load 到相同地址，那么 Load 必须看到刚刚 Store 的值，即使那个 Store 还在重排序单元中排队、尚未提交到内存。
	本质：这是为了维持单核心的自洽性，一个核心总能立即看到自己写入的值。这通常通过“旁路路径”或“存储到加载转发”的硬件机制实现。

### 性能收益与行业现实的讨论
性能收益不确定：从 TSO 迁移到 XC 能带来多少性能提升？没有简单答案。它取决于：
- 微架构细节：比如写缓冲区是简单的 FIFO，还是支持合并写入的更智能设计。
- 推测执行的支持程度：高度推测的核心（如现代高性能CPU）本身就能通过推测隐藏内存延迟，可能从宽松模型中获益较少。

历史观点与现状：
- 1990年代末的预测：有人认为，随着推测执行技术的普及，宽松内存模型的性能优势会减弱，因此主张回归更简单的 SC 或 TSO 接口（对程序员更友好）。
- 现实并未如此发展：
	1.  行业惯性：已有的硬件（如 ARM、PowerPC）和软件生态系统已经建立在宽松模型之上，改变成本巨大。
	2. 核心的多样性：并非所有处理器核心都是高性能、高推测的。在嵌入式系统或众核处理器（尤其是能效优先的领域）中，许多核心是简单、按序执行的。对于这些核心，宽松内存模型允许的硬件优化（简单的乱序窗口、灵活的内存调度）能带来显著的性能/能效收益，而无需复杂的推测硬件。

## 5.3.1 XC 的原子指令
在支持 XC 的系统中，有几种可行的方法来实现原子 RMW 指令。RMW 的实现还取决于系统如何实现 XC；在本节中，我们假设 XC 系统由动态调度的核心组成，每个核心都通过非 FIFO 合并写入缓冲区连接到内存系统。

### 仿照TSO实现
排空写缓冲区，保持该块的读写连贯性权限，执行加载部分和存储部分(直接写入缓存bypassing 写缓冲区)
### 优化方案
仿照TSO方法简单但是牺牲了性能，XC 允许RMW 的加载部分和存储部分都穿过较早的存储，所以只需要获取对应块的读写连贯性权限然后执行加载部分和存储部分。

# 5.3.2 XC FENCE

## 实现 SC

## 排空操作
具体在遇到FENCE 时等待之前的指令全部执行完毕再开始执行 FENCE 之后的指令
- 实现简单
- 性能代价高
- 流水线停滞

## 积极的、非排空的 FENCE
- 思路：不采用完全排空和停顿的方式，而是通过更精细的硬件控制来只强制执行必要的顺序约束，同时允许其他不相关的操作继续执行。
- 如何实现（概念性）：
	- 核心可以继续发射和执行 FENCE 之后的操作（Yi），但硬件必须通过某种机制（如标记、计数、依赖跟踪）来确保：
		- 任何 Yi 操作不能在逻辑上先于任何一个 Xi 操作被全局内存系统观察到。
		- 这通常意味着，即使 Yi 操作被提前执行了，它的结果（对于 Store）或它的请求（对于 Load）也会被硬件暂时“扣住”，直到所有 Xi 操作都已在内存顺序中确立。
- 优点：潜在性能更高。减少了流水线停顿，提高了硬件利用率。
- 缺点：设计和验证极其复杂。需要复杂的硬件状态机和协议来跟踪众多操作之间的顺序依赖关系，确保在高度并发的环境下不出错。
- 现状：现代高性能处理器（尤其是支持宽松模型的）通常会采用这类优化技术，或混合使用方法二和方法三。

# 5.4 无数据竞争程序的 SC
人们总是想要同时获取直观的 SC 和 类XC宽松模型的性能优势，幸运的是这在无数据竞争(data-rate-free， DRF) 程序可以同时实现这两个目标。

用于 DRF 编程的 SC (SC for DRF programming) 要求程序员通过编写正确同步了的程序、并标记同步操作、来确保程序是 SC 下的 DRF (DRF under SC)；然后它要求实现者通过将标记的同步操作映射到宽松内存模型支持的 FENCE 和 RMW 上、来确保宽松模型上 DRF 程序的所有执行也是 SC 执行。XC 和大多数商用的宽松内存模型都有必要的 FENCE 指令和 RMW 来恢复 SC。

使用宽松内存系统的程序员可以通过两种选择来推理他们的程序：

- 他们可以直接使用规则来推理模型允许做什么排序和不允许做什么排序（例如，表 5.5 等），或
- 他们可以插入足够的同步以确保没有数据竞争（仍然允许同步竞争）并使用相对简单的 sequential consistency 模型来推理他们的程序，这种模型似乎永远不会出现程序顺序之外的内存操作。

我们几乎总是推荐后一种 "sequential consistency for data-race-free" 方法，将前一种方法留给编写同步库或设备驱动程序等代码的专家。


# 5.5 一些宽松模型的概念
学术文献提供了许多可供选择的宽松内存模型和概念。在这里，我们从大量文献中回顾一些宽松内存的概念，以提供基本的理解，但全面而正式的探索超出了本入门书的范围。幸运的是，SC for DRF 的用户，可能是大多数程序员，不必掌握这个困难部分中的概念。在第一次通过时，读者可能希望略过或跳过本节。

### 5.5.1 释放一致性

在 Adve 和 Hill 提出 "SC for DRF" 的同一个 ISCA 1990 会议中，Gharachorloo 等人 [20] 提出了释放一致性 (release consistency, RC)。使用本章的术语，RC 的主要观察是使用 FENCE 围绕所有同步操作是多余的。随着对同步的深入了解，同步获取 (acquire) 只需要一个后续的 FENCE，而同步释放 (release) 只需要一个前面的 FENCE。

对于表 5.4 的临界区示例，可以省略 FENCE F11、F14、F21 和 F24。让我们关注 "R11: release(lock)"。FENCE F13 很重要，因为它在锁释放之前对临界区的加载 (L1i) 和存储 (S1j) 进行排序。FENCE F14 可以省略，因为如果核心 C1 的后续内存操作（表中未显示）在释放 R11 之前执行，则没有问题。

RC 实际上允许这些后续操作早在临界区开始时就执行，而 XC 的 FENCE 不允许这样的排序。RC 提供了类似于 FENCE 的 ACQUIRE 和 RELEASE 操作，但仅在一个方向而不是像 FENCE 那样在两个方向上对内存访问进行排序。更一般地说，RC 只需要：

## 核心思想：区分两种同步操作
释放一致性的核心创新在于，它明确区分了两种不同类型的同步操作：

- 获取（Acquire）操作：用于获取对共享数据的访问权。例如：锁获取（lock）、进入临界区、等待信号量。
- 释放（Release）操作：用于释放对共享数据的访问权。例如：锁释放（unlock）、离开临界区、发出信号量。
这种区分基于一个关键观察：在多线程编程中，同步操作通常成对出现，且具有不对称的作用。


## RC 的基本规则
释放一致性对内存操作施加了比 XC 更精细的约束：

规则 1：获取操作的约束
- 获取操作必须在其后的所有普通内存操作之前完成（在全局内存顺序中）。
- 这意味着：获取操作像一个单向屏障——它阻止其之后的普通操作（临界区内的操作）被重排到获取操作之前执行。
- 形式化：Acquire <m 所有后续的普通内存操作
规则 2：释放操作的约束
- 释放操作必须在其前的所有普通内存操作之后完成。
- 这意味着：释放操作像一个单向屏障——它阻止其之前的普通操作（临界区内的操作）被重排到释放操作之后执行。
- 形式化：所有先前的普通内存操作 <m Release
规则 3：同步操作之间的约束
对同一同步变量的释放操作和获取操作之间保持顺序。
例如：线程 A 释放锁 L，线程 B 随后获取锁 L，那么 A 的释放操作必须在 B 的获取操作之前完成。
形式化：Release(L) <m Acquire(L)
规则 3：同步操作之间的约束
- 对同一同步变量的释放操作和获取操作之间保持顺序。
- 例如：线程 A 释放锁 L，线程 B 随后获取锁 L，那么 A 的释放操作必须在 B 的获取操作之前完成。
- 形式化：Release(L) <m Acquire(L)

## 与 XC 的对比
XC 的问题
- 在 XC 中，我们使用 FENCE 来实现同步，但 FENCE 是双向屏障：
- 锁获取后需要 FENCE：阻止其后操作重排到获取之前
- 锁释放前需要 FENCE：阻止其前操作重排到释放之后
这导致了过度约束：FENCE 不仅阻止了必要的顺序，还可能阻止了一些本可以安全重排的操作。
RC 的优势
- RC 通过区分 Acquire 和 Release，实现了更精确的约束：
- Acquire 只约束其后的操作（单向）
- Release 只约束其前的操作（单向）
- 两者都不约束另一方向的操作
这允许更多的优化机会，同时仍能保证正确同步

## RC 的实现机制
硬件实现
现代处理器通常提供专门的指令来实现 RC：
- ARM：LDAR（Load-Acquire）和 STLR（Store-Release）指令
- RISC-V：lr.aq（Load-Reserve with Acquire）和 sc.rl（Store-Conditional with Release）
- x86：大多数普通操作已经具有类似 Acquire/Release 的语义（因为 x86 是 TSO）
软件映射
编译器/运行时将高级语言同步操作映射到硬件指令：
- lock() → 带有 Acquire 语义的加载或特殊指令
- unlock() → 带有 Release 语义的存储或特殊指令


**释放一致性成为现代多处理器系统中事实上的标准内存一致性模型——它在简单性、性能和正确性之间找到了最佳平衡点。**

